# Main system configuration
<system>
  log_level info
</system>

# Source logs from kafka
# https://github.com/fluent/fluent-plugin-kafka
<source>
  @type kafka_group
  consumer_group fluentd
  brokers rs-kafka:9092
  topics stdout-containers
  time_source record
  time_format %iso8601
</source>

<source>
  @type http_healthcheck
  port 8888
  bind 0.0.0.0
</source>

# Define a prometheus input plugin
# to create metrics into a specific endpoint
# https://github.com/fluent/fluent-plugin-prometheus
<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
  aggregated_metrics_path /aggregated_metrics
  # See <transport_tls> to add certificates
</source>
# Enable input stats for prometheus
# https://grafana.com/grafana/dashboards/13042-fluentd-1-x/
<filter **>
  @type prometheus
  @id filter_prometheus
  @log_level warn

  <metric>
    name fluentd_input_status_num_records_total
    type counter
    desc The total number of incoming records
    <labels>
      tag ${tag_parts[0]}
      hostname ${hostname}
    </labels>
  </metric>
</filter>


# If multi-workers fluentd 
# problems to synchronisaze timestamp
# https://grafana.com/docs/loki/latest/clients/fluentd/
# For plugin documentation:
# https://github.com/repeatedly/fluent-plugin-record-modifier
<filter stdout-containers>
    @type record_modifier
    # Change record to get fluentd worker 
    <record>
        swarm_service ${record["container_name"]}
        swarm_service_id ${record["container_name"]}
    </record>
    # Change swarm_service to get only the service name part from the original container_name
    <replace>
        key swarm_service
        expression /^\/{{ role_regards_fluentd_stack_name }}_(?<service_name>[\w_-]+)\.(?<service_id>.+)$/
        replace \k<service_name>
    </replace>
    # Change swarm_service_id to get only the service id part from the original container_name
    # for example:
    # Global service
    # dev-somestack_rs-node-exporter.9s3fznynigx2w2wd1zddui5yp.93rreeiffuxrvg9k76ldanrrj
    #                                                      --> 93rreeiffuxrvg9k76ldanrrj
    # Replicable service:
    # dev-somestack_rs-config.1.ow1ep7oukzuxt3zy523l8qbcc
    #                     --> 1
    <replace>
        key swarm_service_id
        expression /^\/{{ role_regards_fluentd_stack_name }}_[\w_-]+\.((?<service_replica_id>\d+)\..+)|(.+\.(?<service_id>.+))$$/
        replace \k<service_id>\k<service_replica_id>
    </replace>
    # Now we can remove the container_name
    remove_keys container_name
</filter>

# Re-use record_modifier but as output plugin
# Change tag to have swarm_service and source (stdout or stderr) after stdout-containers
# BEFORE : stdout-containers
# AFTER  : stdout-containers_rs-elasticsearch_stdout
# OR       stdout-containers_rs-elasticsearch_stderr
<match stdout-containers>
  @type record_modifier
  tag stdout-containers_${record["swarm_service"]}_${record["source"]}
</match>

<filter stdout-containers_rs-front_stdout>
    @type record_modifier
    # set rs-front stdout to level info
    <record>
        level info
    </record>
    # Remove password in GET params
    <record>
        temp ${if record.has_key?('request'); record['request'] = record['request'].gsub(/(\&password=.+\&)/, '&password=****&'); end; nil}
        temp2 ${if record.has_key?('uri'); record['uri'] = record['uri'].gsub(/(\&password=.+\&)/, '&password=****&'); end; nil}
    </record>
    # temp and temp2 are tmp variable used only for this filter and removed afterward
    remove_keys temp,temp2
</filter>

<filter stdout-containers_rs-gateway_stdout>
    @type record_modifier
    # Remove password in GET params
    <record>
        temp ${if record.has_key?('message'); record['message'] = record['message'].gsub(/(\&password=.+\&)/, '&password=****&'); end; nil}
    </record>
    # temp is a tmp variable used only for this filter and removed afterward
    remove_keys temp
</filter>

<filter stdout-containers_rs-front_stderr>
    @type record_modifier
    # set rs-front sdterr to level error
    <record>
        level error
    </record>
</filter>

<filter stdout-containers_**>
    @type record_modifier
    # set record.level = unknown when the level is not already provided in the record
    # https://grafana.com/docs/grafana/latest/explore/logs-integration/#log-level
    <record>
        temp ${unless record.has_key?('level'); record['level'] = 'unknown'; end; nil}
    </record>
    # temp is a tmp variable used only for this filter and removed afterward
    # also remove source (stdout or stderr)
    remove_keys temp,source
</filter>

# Ensure level is up case
<filter stdout-containers_**>
    @type record_modifier
    <record>
      level ${record["level"].upcase}
    </record>
</filter>

# See https://grafana.com/docs/loki/latest/clients/fluentd/
# match ** seems to raise an error to send to loki
# (400 Bad Request error at least one label pair is required per stream)
# so we prefix kafka logs by stdout-containers_
<match stdout-containers_**>
  @type loki
  url "http://rs-loki:3100"
  line_format json
  # Remove fluentd_thread in loki logs
  include_thread_label false
  <label>
    fluentd_worker
    swarm_service
    swarm_node hostname
    swarm_service_id
    level
    current_tag $.tag
  </label>
  <buffer>
    chunk_limit_size    8m   # default 8m (MB)
    flush_thread_count  8
    queue_limit_length  32
    overflow_action     block
    # https://docs.fluentd.org/v/0.12/buffer/memory
    flush_interval      2s   # default 60s
    flush_at_shutdown   true # default true
  </buffer>
</match>
