---
# Stack infos
role_regards_stack_stack_name: "{{ group_stack_name }}"

# Folder structure
role_regards_stack_workspace_local: "{{ group_workdir_local }}{{ group_stack_name }}/workspace/"
role_regards_stack_config: "{{ group_workdir_local }}{{ group_stack_name }}/config/"
role_regards_stack_logback: "{{ role_regards_stack_config }}regards/logback/"
role_regards_stack_stack: "{{ group_workdir_local }}{{ group_stack_name }}/stack/"
role_regards_stack_cli: "{{ group_workdir_local }}{{ group_stack_name }}/cli/"

# Files owners
role_regards_stack_container_root_user: "{{ group_container_root_user }}"
role_regards_stack_container_root_group: "{{ group_container_root_group }}"

# Docker users
role_regards_stack_container_run_uid: "{{ group_container_run_uid }}"
role_regards_stack_container_run_gid: "{{ group_container_run_gid }}"

# Docker conf
role_regards_stack_docker_network_name: "{{ group_docker_network_name }}"
role_regards_stack_registry: "{{ group_docker_registry }}"

# List of microservices to run (with config), COTS to deploy and infos to access to these COTS
role_regards_stack_mservices: "{{ group_docker_mservices }}"
role_regards_stack_cots: "{{ group_docker_cots }}"
role_regards_stack_cots_configuration: "{{ group_docker_cots_configuration }}"
role_regards_stack_workers: "{{ group_docker_workers | default([]) }}"

role_regards_stack_mservices_admin_image_name: "{{ (group_docker_mservices.admin | default({})).get('imageName', 'rs-admin') }}"
role_regards_stack_mservices_admin_instance_image_name: "{{ (group_docker_mservices.admin_instance | default({})).get('imageName', 'rs-admin-instance') }}"

role_regards_stack_mservices_access_instance_image_name: "rs-access-instance{{ ( (group_docker_mservices.access_instance | default({})).get('postgis', true) == false) | ternary('-light', '') }}"

postgres_default:
  user: azertyuiop123456789
  password: azertyuiop123456789

role_regards_stack_config_postgres:
  user: "{{ (group_config_mservices.postgres | default({})).get('instance', {}).get('user', postgres_default.user) }}"
  password: "{{ (group_config_mservices.postgres | default({})).get('instance', {}).get('user', postgres_default.password) }}"

rabbitmq_default:
  use_longname: true
  manual_revision: '1'

role_regards_stack_config_rabbitmq_use_longname: "{{ group_docker_cots.get('rabbitmq', {}).get('use_longname', rabbitmq_default.use_longname) }}"
role_regards_stack_rabbitmq_manual_revision: "{{ group_docker_cots.get('rabbitmq', {}).get('manual_revision', rabbitmq_default.manual_revision) }}"

role_regards_stack_public_url: "{{ group_docker_mservices.front.protocol }}:\\/\\/{{ group_docker_mservices.front.host }}:{{ group_docker_mservices.front.public_port | default(group_docker_mservices.front.port) }}"

# Minio
role_regards_stack_minio_public_url: "http://{{ group_docker_mservices.front.host }}"

role_regards_stack_ca_certificates: "{{ group_config_mservices.get('ca_certificates', []) }}"

# Top level volumes / configs / secrets and REGARDS related volumes
role_regards_stack_top_level_nfs_servers: "{{ (group_docker_mounts | default({})).get('nfs', []) }}"
role_regards_stack_top_level_volumes: "{{ (group_docker_mounts | default({})).get('volumes', []) }}"
role_regards_stack_top_level_configs: "{{ (group_docker_mounts | default({})).get('configs', []) }}"
role_regards_stack_top_level_secrets: "{{ (group_docker_mounts | default({})).get('secrets', []) }}"
role_regards_stack_top_level_regards: "{{ (group_docker_mounts | default({})).get('regards', {}) }}"

role_regards_stack_volume_data_inputs: "{{ role_regards_stack_top_level_regards.get('data_inputs', []) }}"

role_regards_stack_volume_processing: "{{ role_regards_stack_top_level_regards.get('processing', {}) }}"
role_regards_stack_volume_dam_attachment_storage: "{{ role_regards_stack_top_level_regards.get('dam', {}) }}"
role_regards_stack_volume_dam_attachment_input: "{{ role_regards_stack_top_level_regards.get('storage', {}).get('dataset_attachment', {}) }}"
role_regards_stack_volume_storage_online: "{{ role_regards_stack_top_level_regards.get('storage', {}).get('online', {}) }}"
role_regards_stack_volume_storage_cache: "{{ role_regards_stack_top_level_regards.get('storage', {}).get('cache', {}) }}"

role_regards_stack_volume_workspace: "{{ role_regards_stack_top_level_regards.get('workspace', {}) }}"
role_regards_stack_volume_logs: "{{ role_regards_stack_top_level_regards.get('logs', {}) }}"
role_regards_stack_volume_plugins: "{{ role_regards_stack_top_level_regards.get('plugins', {}) }}"

# Fluent conf
# When true, all microservices write logs on the same network file system
role_regards_stack_all_logs_inside_same_network_storage: "{{ role_regards_stack_volume_logs.nfs is defined }}"

# Log configuration
# When true, services do not define any "logging" configuration
# As the conf to reach the log concentrator is defined in the docker daemon conf file
role_regards_stack_initialize_default_logging: "{{ group_docker_use_log_concentrator is not defined or not group_docker_use_log_concentrator|bool }}"

role_regards_stack_volume_mservices_logs:
  - config
  - registry
  - gateway
  - admin-instance
  - admin
  - authentication
  - dam
  - notifier
  - fem
  - catalog
  - access-instance
  - access-project
  - storage
  - order
  - processing
  - ingest
  - dataprovider
  - worker-manager
  - lta-manager
  - file-catalog
  - file-access
  - file-packager
  - delivery
  - front

role_regards_stack_volume_elasticsearch_logs: "{{ (group_docker_mounts | default({})).get('elasticsearch_logs', {}) }}"
role_regards_stack_volume_elasticsearch_logs_data: "{{ role_regards_stack_volume_elasticsearch_logs.get('data', {}) }}"
role_regards_stack_volume_elasticsearch_logs_backup: "{{ role_regards_stack_volume_elasticsearch_logs.get('backup', {}) }}"

role_regards_stack_volume_rabbitmq_data: "{{ (group_docker_mounts | default({})).get('rabbitmq', {}) }}"
role_regards_stack_volume_postgres_data: "{{ (group_docker_mounts | default({})).get('postgresql', {}) }}"

role_regards_stack_top_level_secrets_location: "{{ group_workdir_local }}{{ group_stack_name }}/config/mounted/secrets"
role_regards_stack_top_level_configs_location: "{{ group_workdir_local }}{{ group_stack_name }}/config/mounted/configs"


# Certificates
role_regards_stack_rabbitmq_ssl_active: "{{ group_docker_cots_configuration.get('rabbitmq', {}).ssl is defined }}"
role_regards_stack_rabbitmq_folder_certificates: "{{ group_workdir_local }}{{ group_stack_name }}/config/rabbitmq/ca-certificates/"
role_regards_stack_rabbitmq_ssl_certificates_conf: "{{ group_docker_cots_configuration.get('rabbitmq', {}).get('ssl', {}) }}"

# Healthcheck
role_regards_stack_enable_mservices_healthcheck: "{{ (group_config_mservices | default({})).get('enable_healthcheck', false) | bool }}"
role_regards_stack_enable_cots_healthcheck: "{{ (group_docker_cots_configuration | default({})).get('enable_healthcheck', false) | bool }}"

# Resource limits
role_regards_stack_enable_mservices_resource_limits: "{{ (group_config_mservices | default({})).get('enable_resource_limits', false) | bool }}"
role_regards_stack_enable_cots_resource_limits: "{{ (group_docker_cots_configuration | default({})).get('enable_resource_limits', false) | bool }}"

role_regards_stack_resource_limits:
# COTS
  rabbitmq:
    limits:
      cpus: '4'
      memory: "{{ group_docker_cots.get('rabbitmq', {}).get('containerLimit', '2500m') }}"
      pids: 100000
    reservations:
      cpus: '1'
      memory: "{{ group_docker_cots.get('rabbitmq', {}).get('memoryLimit', '2000m') }}"
  phppgadmin:
    limits:
      cpus: "{{ group_docker_cots.get('phppgadmin', {}).get('cpuLimit', '0.5') }}"
      memory: "{{ group_docker_cots.get('phppgadmin', {}).get('memoryLimit', '256m') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_cots.get('phppgadmin', {}).get('cpuReserved', '0.01') }}"
      memory: "{{ group_docker_cots.get('phppgadmin', {}).get('memoryReserved', '32m') }}"
  postgres:
    limits:
      cpus: "{{ group_docker_cots.get('postgres', {}).get('cpuLimit', '1') }}"
      memory: "{{ group_docker_cots.get('postgres', {}).get('memoryLimit', '1G') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_cots.get('postgres', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_cots.get('postgres', {}).get('memoryReserved', '256M') }}"
  # Microservices
  # CPU limit is tailored to handle microservice boot time
  config:
    limits:
      cpus: "{{ group_docker_mservices.get('config', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('config', {}).get('memoryLimit', '512mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('config', {}).get('cpuReserved', '0.25') }}"
      memory: "{{ group_docker_mservices.get('config', {}).get('memoryReserved', '128mb') }}"
  registry:
    limits:
      cpus: "{{ group_docker_mservices.get('registry', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('registry', {}).get('memoryLimit', '512mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('registry', {}).get('cpuReserved', '0.25') }}"
      memory: "{{ group_docker_mservices.get('registry', {}).get('memoryReserved', '128mb') }}"
  gateway:
    limits:
      cpus: "{{ group_docker_mservices.get('gateway', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('gateway', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('gateway', {}).get('cpuReserved', '0.25') }}"
      memory: "{{ group_docker_mservices.get('gateway', {}).get('memoryReserved', '256mb') }}"
  admin_instance:
    limits:
      cpus: "{{ group_docker_mservices.get('admin_instance', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('admin_instance', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('admin_instance', {}).get('cpuReserved', '0.50') }}"
      memory: "{{ group_docker_mservices.get('admin_instance', {}).get('memoryReserved', '512mb') }}"
  admin:
    limits:
      cpus: "{{ group_docker_mservices.get('admin', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('admin', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('admin', {}).get('cpuReserved', '0.50') }}"
      memory: "{{ group_docker_mservices.get('admin', {}).get('memoryReserved', '768mb') }}"
  authentication:
    limits:
      cpus: "{{ group_docker_mservices.get('authentication', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('authentication', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('authentication', {}).get('cpuReserved', '0.25') }}"
      memory: "{{ group_docker_mservices.get('authentication', {}).get('memoryReserved', '256mb') }}"
  dam:
    limits:
      cpus: "{{ group_docker_mservices.get('dam', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('dam', {}).get('memoryLimit', '1280mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('dam', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('dam', {}).get('memoryReserved', '1024mb') }}"
  notifier:
    limits:
      cpus: "{{ group_docker_mservices.get('notifier', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('notifier', {}).get('memoryLimit', '1280mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('notifier', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('notifier', {}).get('memoryReserved', '1024mb') }}"
  fem:
    limits:
      cpus: "{{ group_docker_mservices.get('fem', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('fem', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('fem', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('fem', {}).get('memoryReserved', '1024mb') }}"
  catalog:
    limits:
      cpus: "{{ group_docker_mservices.get('catalog', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('catalog', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('catalog', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('catalog', {}).get('memoryReserved', '1024mb') }}"
  access_instance:
    limits:
      cpus: "{{ group_docker_mservices.get('access_instance', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('access_instance', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('access_instance', {}).get('cpuReserved', '0.25') }}"
      memory: "{{ group_docker_mservices.get('access_instance', {}).get('memoryReserved', '512mb') }}"
  access_project:
    limits:
      cpus: "{{ group_docker_mservices.get('access_project', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('access_project', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('access_project', {}).get('cpuReserved', '0.25') }}"
      memory: "{{ group_docker_mservices.get('access_project', {}).get('memoryReserved', '512mb') }}"
  front:
    limits:
      cpus: "{{ group_docker_mservices.get('front', {}).get('cpuLimit', '1') }}"
      memory: "{{ group_docker_mservices.get('front', {}).get('memoryLimit', '256mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('front', {}).get('cpuReserved', '0.1') }}"
      memory: "{{ group_docker_mservices.get('front', {}).get('memoryReserved', '64mb') }}"
  storage:
    limits:
      cpus: "{{ group_docker_mservices.get('storage', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('storage', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('storage', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('storage', {}).get('memoryReserved', '1024mb') }}"
  order:
    limits:
      cpus: "{{ group_docker_mservices.get('order', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('order', {}).get('memoryLimit', '1280mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('order', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('order', {}).get('memoryReserved', '1024mb') }}"
  processing:
    limits:
      cpus: "{{ group_docker_mservices.get('processing', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('processing', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('processing', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('processing', {}).get('memoryReserved', '1024mb') }}"
  ingest:
    limits:
      cpus: "{{ group_docker_mservices.get('ingest', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('ingest', {}).get('memoryLimit', '1536mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('ingest', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('ingest', {}).get('memoryReserved', '1024mb') }}"
  dataprovider:
    limits:
      cpus: "{{ group_docker_mservices.get('dataprovider', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('dataprovider', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('dataprovider', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('dataprovider', {}).get('memoryReserved', '1024mb') }}"
  worker_manager:
    limits:
      cpus: "{{ group_docker_mservices.get('worker_manager', {}).get('cpuLimit', '4') }}"
      memory: "{{ group_docker_mservices.get('worker_manager', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('worker_manager', {}).get('cpuReserved', '1') }}"
      memory: "{{ group_docker_mservices.get('worker_manager', {}).get('memoryReserved', '1024mb') }}"
  lta_manager:
    limits:
      cpus: "{{ group_docker_mservices.get('lta_manager', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('lta_manager', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('lta_manager', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('lta_manager', {}).get('memoryReserved', '512mb') }}"
  delivery:
    limits:
      cpus: "{{ group_docker_mservices.get('delivery', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('delivery', {}).get('memoryLimit', '1024mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('delivery', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('delivery', {}).get('memoryReserved', '512mb') }}"
  file_catalog:
    limits:
      cpus: "{{ group_docker_mservices.get('file_catalog', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('file_catalog', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('file_catalog', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('file_catalog', {}).get('memoryReserved', '512mb') }}"
  file_access:
    limits:
      cpus: "{{ group_docker_mservices.get('file_access', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('file_access', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('file_access', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('file_access', {}).get('memoryReserved', '512mb') }}"
  file_packager:
    limits:
      cpus: "{{ group_docker_mservices.get('file_packager', {}).get('cpuLimit', '3') }}"
      memory: "{{ group_docker_mservices.get('file_packager', {}).get('memoryLimit', '768mb') }}"
      pids: 100000
    reservations:
      cpus: "{{ group_docker_mservices.get('file_packager', {}).get('cpuReserved', '0.5') }}"
      memory: "{{ group_docker_mservices.get('file_packager', {}).get('memoryReserved', '512mb') }}"

role_regards_stack_front_securised: "{{ (group_docker_mservices.front | default({})).get('securised', false) | bool }}"
role_regards_stack_front_healthcheck_url: "{{ group_docker_mservices.front.host }}:{{ group_docker_mservices.front.public_port | default(group_docker_mservices.front.port) }}"
role_regards_stack_front_has_rabbitmq_admin: "{{ (group_docker_mservices.front | default({})).rabbitmq_admin is defined }}"

role_regards_stack_restart_policy:
  delay: "{{ (group_docker_restart_policy | default({})).get('delay', '10s') }}"
  # Do not use large max_attemps as it can destroy a cluster
  # @see https://github.com/moby/moby/issues/35637
  max_attempts: "{{ (group_docker_restart_policy | default({})).get('max_attempts', '0') }}"
  window: "{{ (group_docker_restart_policy | default({})).get('window', '0s') }}"
