# We dont use * in tail anymore, some files were not tracked
# Allows us to define a specific behavior for the front error log file
<source>
    @type tail
    path /logs/access-instance/rs-access-instance.log
    pos_file /tmp/fluentd-access-instance.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/catalog/rs-catalog.log
    pos_file /tmp/fluentd-catalog.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/registry/rs-registry.log
    pos_file /tmp/fluentd-registry.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/access-project/rs-access-project.log
    pos_file /tmp/fluentd-access.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/config/rs-config.log
    pos_file /tmp/fluentd-config.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/gateway/rs-gateway.log
    pos_file /tmp/fluentd-gateway.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/storage/rs-storage.log
    pos_file /tmp/fluentd-storage.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/admin/rs-admin.log
    pos_file /tmp/fluentd-admin.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/dam/rs-dam.log
    pos_file /tmp/fluentd-dam.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/ingest/rs-ingest.log
    pos_file /tmp/fluentd-ingest.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/admin-instance/rs-admin-instance.log
    pos_file /tmp/fluentd-admin-instance.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/dataprovider/rs-dataprovider.log
    pos_file /tmp/fluentd-dataprovider.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/notifier/rs-notifier.log
    pos_file /tmp/fluentd-notifier.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/authentication/rs-authentication.log
    pos_file /tmp/fluentd-authentication.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/fem/rs-fem.log
    pos_file /tmp/fluentd-fem.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/worker-manager/rs-worker-manager.log
    pos_file /tmp/fluentd-worker-manager.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/lta-manager/rs-lta-manager.log
    pos_file /tmp/fluentd-lta-manager.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/processing/rs-processing.log
    pos_file /tmp/fluentd-processing.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>
<source>
    @type tail
    path /logs/order/rs-order.log
    pos_file /tmp/fluentd-order.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>

{% for worker in role_regards_fluentd_workers %}
<source>
    @type tail
    path /logs/{{worker.name}}/{{worker.name}}.log
    pos_file /tmp/{{worker.name}}.pos
    read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type none
    </parse>
</source>

{% endfor %}
<source>
    @type tail
    path /logs/front/access.log
    pos_file /tmp/fluentd-front-access.pos
    # These files are not rotated. It's dangerous to rescan them from head
    # read_from_head true
    refresh_interval 5
    tag docker.*
    <parse>
        @type json
    </parse>
</source>
<source>
    @type tail
    path /logs/front/error.log
    pos_file /tmp/fluentd-front-error.pos
    # These files are not rotated. It's dangerous to rescan them from head
    # read_from_head true
    refresh_interval 5
    # Specific tag
    tag front-error
    <parse>
        @type none
    </parse>
</source>

# The tag looks like docker.logs.access-instance.rs-access-instance.log
<filter docker.**.log>
    @type record_transformer
    enable_ruby
    <record>
        foldername ${tag_parts[2]}
    </record>
    remove_keys log, attrs
</filter>

# Reduce the tag to the folder name
<match docker.**>
    @type rewrite_tag_filter
    <rule>
        key foldername
        pattern /(.*)/
        tag $1
    </rule>
</match>

# Identify the date from Âµservices logs
# To create a single log from several lines (waits for the next date)
<filter config registry gateway admin-instance admin authentication dam notifier fem catalog access-instance access-project storage order ingest dataprovider processing worker-manager lta-manager{% for worker in role_regards_fluentd_workers %} {{worker.name}}{% endfor %}>
    @type concat
    key message
    # Regards log4j date format
    # 2020-04-30 04:57:31,489
    # \x00\x002020-04-30 04:57:31,489
    # -2020-04-30 04:57:31,489
    multiline_start_regexp /^(?:\\x00)*-?\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{1,3}/
    timeout_label @PARSEJAVA
</filter>

# Send log4j logs to @PARSEJAVA
<match config registry gateway admin-instance admin authentication dam notifier fem catalog access-instance access-project storage order ingest dataprovider processing worker-manager lta-manager{% for worker in role_regards_fluentd_workers %} {{worker.name}}{% endfor %}>
  @type relabel
  @label @PARSEJAVA
</match>

# Send front logs to @PARSENGINX
<match front>
  @type relabel
  @label @PARSENGINX
</match>

# Send front error logs to @PARSENGINXERRORS
<match front-error>
  @type relabel
  @label @PARSENGINXERRORS
</match>

# Otherwise send RAW (fields won't be extracted) to ES
<match **>
  @type relabel
  @label @OUTPUT
</match>

# parse the entire log output to extract several fields using named regex group
<label @PARSEJAVA>
    <filter config registry gateway admin-instance admin authentication dam notifier fem catalog access-instance access-project storage order ingest dataprovider processing worker-manager lta-manager>
        @type parser
        key_name message
        <parse>
            @type regexp
            expression /^(?:\\x00)*-?(?<logtime>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{1,3})\s+\[(?<microservice_name>[^\]]+)\]\s+\[(?<thread>[^\]]+)\s*\]\s+(?<loglevel>[^\s]+)\s+(?<class>[^\]\s]*)\s?\.?\[(?<tenant>[^\]\s]+)?\]\s?\.?(?<remoteHost>[^\s]+)?\s?\.?(?<xForwardedFor>[^\]\[]+)?\s?\.?(?<username>[^\]\[\s]+)?\s\[(?<correlation_id>[^\]\s]+)?\]\s-\s(?<message>.*)$/
            time_key logtime
            time_format %Y-%m-%d %H:%M:%S,%N
        </parse>
    </filter>
{% if role_regards_fluentd_workers|length>0 %}
    <filter {% for worker in role_regards_fluentd_workers %} {{worker.name}}{% endfor %}>
        @type parser
        key_name message
        <parse>
            @type regexp
            expression /^(?:\\x00)*-?(?<logtime>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{1,3})\s+\[(?<microservice_name>[^\]]+)\]\s+\[(?<thread>[^\]]+)\s*\]\s+(?<loglevel>[^\s]+)\s+(?<class>[^\]\s]*)\s+?-\s(?<message>.*)$/
            time_key logtime
            time_format %Y-%m-%d %H:%M:%S,%N
        </parse>
    </filter>
{% endif %}
    <match **>
        @type copy
        <store>
            @type relabel
            @label @OUTPUT
        </store>
    </match>
</label>

# Use NGINX parse for front logs
<label @PARSENGINX>
    <filter front>
        @type record_transformer
        enable_ruby
        <record>
            message "${record['status']} - ${record['request']}"
            request_time ${record['request_time'].to_f}
            body_bytes_sent ${record['body_bytes_sent'].to_f}
            loglevel INFO
        </record>
        remove_keys foldername
    </filter>
    <match **>
        @type copy
        <store>
            @type relabel
            @label @OUTPUT
        </store>
    </match>
</label>

# Use nginx error parser from front logs
<label @PARSENGINXERRORS>
    <filter front-error>
        # Handle errors
        @type parser
        key_name message
        <parse>
            @type regexp
            expression /^(?<logtime>\d{4}\/\d{1,2}\/\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}) \[(?<loglevel>[^\s]+)\] (?<message>.*)$/
            time_key logtime
            time_format %Y/%m/%d %H:%M:%S
        </parse>
    </filter>
    <match **>
        @type copy
        <store>
            @type relabel
            @label @OUTPUT
        </store>
    </match>
</label>

# Save the output to ES
<label @OUTPUT>
    <match **>
        @type copy
        <store>
            @type elasticsearch
            host rs-logs-elasticsearch
            port 9200
            logstash_format true
            logstash_prefix regards-log
            # next 3 lines should allow to handle connections issues with ES via containers
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_timestamp true
            include_tag_key true
            type_name access_log
            tag_key @log_name
            <buffer>
                @type file
                path /fluentd/logs
                flush_thread_count 8
                flush_interval 1s
                chunk_limit_size 32M
                queue_limit_length 4
                flush_mode interval
                retry_max_interval 30
                retry_forever true
                # Block all tail sources if buffer overflows
                overflow_action block
            </buffer>
        </store>
    </match>
</label>
